{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "import string\n",
    "import re\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function : Create unigram dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_unigrams(unigrams,unigram):\n",
    "    for uni in unigrams:\n",
    "        stri = ''.join(uni)\n",
    "        if not unigram or stri not in unigram:\n",
    "            unigram[stri] = 1;\n",
    "        else:\n",
    "            unigram[stri] = unigram[stri] + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function : Create bigram dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_bigrams(bigrams,bigram):\n",
    "    for bi in bigrams:\n",
    "        stri = ' '.join(bi)\n",
    "        if not bigram or stri not in bigram:\n",
    "            bigram[stri] = 1;\n",
    "        else:\n",
    "            bigram[stri] = bigram[stri] + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function : Create trigram dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_trigrams(trigrams,trigram):\n",
    "    for tri in trigrams:\n",
    "        stri = ' '.join(tri)\n",
    "        if not trigram or stri not in trigram:\n",
    "            trigram[stri] = 1;\n",
    "        else:\n",
    "            trigram[stri] = trigram[stri] + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function : Create quadgram dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_quadgrams(quadgrams,quadgram):\n",
    "    for quad in quadgrams:\n",
    "        stri = ' '.join(quad)\n",
    "        if not quadgram or stri not in quadgram:\n",
    "            quadgram[stri] = 1;\n",
    "        else:\n",
    "            quadgram[stri] = quadgram[stri] + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function : Create probability dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def add_probability(unigram,bigram,trigram,quadgram,probab,tokens):\n",
    "    lambda1 = 0.25\n",
    "    lambda2 = 0.25\n",
    "    lambda3 = 0.25\n",
    "    lambda4 = 0.25\n",
    "    for quad in quadgram:\n",
    "        #print(quad)\n",
    "        s = quad.split()\n",
    "        #print(s)\n",
    "        w = s[-1]\n",
    "        stri = ' '.join(s[0:3])\n",
    "        #print(stri)\n",
    "        p = ( lambda1 * (quadgram[quad]/trigram[stri])) + (lambda2 * (trigram[' '.join(s[1:4])]/bigram[' '.join(s[1:3])])) + (lambda3 * (bigram[' '.join(s[2:4])]/unigram[str(s[2])])) + (lambda4 * (unigram[str(s[3])]/tokens))\n",
    "        if stri in probab:\n",
    "            if w not in probab[stri] :\n",
    "                probab[stri][w] = p\n",
    "                d = OrderedDict(sorted(probab[stri].items(), key=lambda t: t[1]))\n",
    "                probab[stri] = d\n",
    "        else:\n",
    "            probab[stri] = {}\n",
    "            probab[stri][w] = p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function : Create vocabulary list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_token_list(tokens,vocab):\n",
    "    newlist=[]\n",
    "    for word in tokens:\n",
    "        if word:\n",
    "            if not vocab or word not in vocab: \n",
    "                vocab[word] = len(vocab)\n",
    "            newlist.append(str(vocab[word]))\n",
    "    return newlist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function : Remove punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_punc(text):\n",
    "    for c in string.punctuation:\n",
    "        if c!='\\'':\n",
    "            text=text.replace(c,\" \")\n",
    "    text = text.replace(\"' \",\" \")\n",
    "    text = text.replace(\"\\n\",\" \")\n",
    "    answer = text.lower()\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function : Tokenize the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenize(text, ngrams,vocab):\n",
    "    clean_text = remove_punc(text)\n",
    "    tokens = create_token_list(clean_text.split(),vocab)\n",
    "    #print(tokens)\n",
    "    return [tuple(tokens[i:i+ngrams]) for i in range(len(tokens)-ngrams+1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function : Predict word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predictWord(s,probab,vocab,rank = 0):\n",
    "    predict = \"\"\n",
    "    if s in probab:\n",
    "        predict = list(probab[s].keys())[-1 - rank]\n",
    "    return predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing performed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_data(unigram,bigram,trigram,quadgram,vocab):\n",
    "    l = 0\n",
    "    with open('training_corpus.txt',buffering=20000,encoding='latin1') as f:\n",
    "        for line in f:\n",
    "            data = tokenize(line,1,vocab)\n",
    "            add_unigrams(data,unigram)\n",
    "            l = l + len(data)\n",
    "            data = tokenize(line,2,vocab)\n",
    "            add_bigrams(data,bigram)\n",
    "            data = tokenize(line,3,vocab)\n",
    "            add_trigrams(data,trigram)\n",
    "            data = tokenize(line,4,vocab)\n",
    "            add_quadgrams(data,quadgram)\n",
    "    f.close()\n",
    "    return l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function : Calculate score for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calculate_score(probab,vocab):\n",
    "    score = 0\n",
    "    l = list(vocab.keys())\n",
    "    with open('testing_corpus.txt',buffering=20000,encoding='latin1') as f:\n",
    "        for line in f:\n",
    "            text = remove_punc(line)\n",
    "            tokens = text.split()\n",
    "            data = [tuple(tokens[i:i+4]) for i in range(len(tokens)-4+1)]            \n",
    "            for quad in data:\n",
    "                numbers = []\n",
    "                flag = 0\n",
    "                for ele in quad:\n",
    "                    if ele in vocab:\n",
    "                        numbers.append(str(vocab[ele]))\n",
    "                    else:\n",
    "                        flag = 1\n",
    "                        break\n",
    "                if flag == 0:\n",
    "                    tri = ' '.join(numbers).split()\n",
    "                    w = tri[-1]\n",
    "                    del tri[-1]\n",
    "                    s = ' '.join(tri)\n",
    "                    predict = predictWord(s,probab,vocab)\n",
    "                    if w == predict:\n",
    "                        score = score + 1\n",
    "                        #print(score,',',w,',',predict)\n",
    "                        #print(l[(int)(numbers[0])],' ',l[(int)(numbers[1])],' ',l[(int)(numbers[2])],' ',l[(int)(numbers[3])])\n",
    "    f.close()\n",
    "    print(\"Score : \",score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function : Calculate Perplexity after Add-1 Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_Perplexity(n,vocab,trigram,quadgram):\n",
    "    p = 1.0\n",
    "    with open('testing_corpus.txt',buffering=20000,encoding='latin1') as f:\n",
    "        for line in f:\n",
    "            text = remove_punc(line)\n",
    "            tokens = text.split()\n",
    "            data = [tuple(tokens[i:i+4]) for i in range(len(tokens)-4+1)] \n",
    "            for quad in data:\n",
    "                count_quadgrams = 1\n",
    "                count_trigrams = len(quadgram)\n",
    "                numbers = []\n",
    "                flag = 0\n",
    "                for ele in quad:\n",
    "                    if ele in vocab:\n",
    "                        numbers.append(str(vocab[ele]))\n",
    "                    else:\n",
    "                        flag = 1\n",
    "                        break\n",
    "                if flag == 0:\n",
    "                    four = ' '.join(numbers)\n",
    "                    three = ' '.join(numbers[0:3])\n",
    "                    if three in trigram:\n",
    "                        count_trigrams = count_trigrams + trigram[three]\n",
    "                    if four in quadgram:\n",
    "                        count_quadgrams = count_quadgrams + quadgram[four]\n",
    "                p=p*(((1/float(count_quadgrams))*count_trigrams)**(1./n))\n",
    "    print(\"Quadgram Perplexity : \",p)        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score :  2038\n",
      "Quadgram Perplexity :  2.680661462804432\n",
      "Score :  2038\n",
      "Quadgram Perplexity :  2.680661462804432\n",
      "Score :  2038\n",
      "Quadgram Perplexity :  2.680661462804432\n",
      "Score :  2038\n",
      "Quadgram Perplexity :  2.680661462804432\n",
      "1 loop, best of 3: 33.2 s per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "def main():\n",
    "    vocab = {}\n",
    "    probab = {}\n",
    "    unigram = {}\n",
    "    bigram = {}\n",
    "    trigram = {}\n",
    "    quadgram = {}\n",
    "    n = train_data(unigram,bigram,trigram,quadgram,vocab)\n",
    "    add_probability(unigram,bigram,trigram,quadgram,probab,n)\n",
    "    #print(\"V : \",len(vocab),\" n : \",n)\n",
    "    calculate_score(probab,vocab)\n",
    "    calculate_Perplexity(n,vocab,trigram,quadgram)\n",
    "if __name__== \"__main__\":\n",
    "  main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
