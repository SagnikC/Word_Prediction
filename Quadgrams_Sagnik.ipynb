{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function : Create trigram dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_trigrams(trigrams,trigram):\n",
    "    for tri in trigrams:\n",
    "        stri = ' '.join(tri)\n",
    "        if not trigram or stri not in trigram:\n",
    "            trigram[stri] = 1;\n",
    "        else:\n",
    "            trigram[stri] = trigram[stri] + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function : Create quadgram dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_quadgrams(quadgrams,quadgram):\n",
    "    for quad in quadgrams:\n",
    "        stri = ' '.join(quad)\n",
    "        if not quadgram or stri not in quadgram:\n",
    "            quadgram[stri] = 1;\n",
    "        else:\n",
    "            quadgram[stri] = quadgram[stri] + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function : Create probability dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def add_probability(trigram,quadgram,probab):\n",
    "    for quad in quadgram:\n",
    "        #print(quad)\n",
    "        s = quad.split()\n",
    "        #print(s)\n",
    "        w = s[-1]\n",
    "        del s[-1]\n",
    "        stri = ' '.join(s)\n",
    "        #print(stri)\n",
    "        p = quadgram[quad]/trigram[stri]\n",
    "        if stri in probab:\n",
    "            if p > probab[stri][1]:\n",
    "                probab[stri][0] = w\n",
    "                probab[stri][1] = p\n",
    "        else:\n",
    "            probab.setdefault(stri,[])\n",
    "            probab[stri].append(w)\n",
    "            probab[stri].append(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function : Create vocabulary list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_token_list(tokens,vocab):\n",
    "    newlist=[]\n",
    "    for word in tokens:\n",
    "        if word:\n",
    "            if not vocab or word not in vocab: \n",
    "                vocab[word] = len(vocab)\n",
    "            newlist.append(str(vocab[word]))\n",
    "    return newlist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function : Remove punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_punc(text):\n",
    "    for c in string.punctuation:\n",
    "        if c!='\\'':\n",
    "            text=text.replace(c,\" \")\n",
    "    text = text.replace(\"' \",\" \")\n",
    "    text = text.replace(\"\\n\",\" \")\n",
    "    answer = text.lower()\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function : Tokenize the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenize(text, ngrams,vocab):\n",
    "    clean_text = remove_punc(text)\n",
    "    tokens = create_token_list(clean_text.split(),vocab)\n",
    "    #print(tokens)\n",
    "    return [tuple(tokens[i:i+ngrams]) for i in range(len(tokens)-ngrams+1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function : Predict word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predictWord(s,probab,vocab):\n",
    "    predict = \"\"\n",
    "    if s in probab:\n",
    "        predict = probab[s][0]\n",
    "    return predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing performed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_data(trigram,quadgram,vocab):\n",
    "    l = 0\n",
    "    with open('corpusfile1.txt',buffering=20000,encoding='latin1') as f:\n",
    "        for line in f:\n",
    "            data = tokenize(line,3,vocab)\n",
    "            #print(data)\n",
    "            add_trigrams(data,trigram)\n",
    "            data = tokenize(line,4,vocab)\n",
    "            l = l + len(data)\n",
    "            add_quadgrams(data,quadgram)\n",
    "    f.close()\n",
    "    return l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function : Calculate score for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calculate_score(probab,vocab):\n",
    "    score = 0\n",
    "    l = list(vocab.keys())\n",
    "    with open('testfile.txt',buffering=20000,encoding='latin1') as f:\n",
    "        for line in f:\n",
    "            text = remove_punc(line)\n",
    "            tokens = text.split()\n",
    "            data = [tuple(tokens[i:i+4]) for i in range(len(tokens)-4+1)]            \n",
    "            for quad in data:\n",
    "                numbers = []\n",
    "                flag = 0\n",
    "                for ele in quad:\n",
    "                    if ele in vocab:\n",
    "                        numbers.append(str(vocab[ele]))\n",
    "                    else:\n",
    "                        flag = 1\n",
    "                        break\n",
    "                if flag == 0:\n",
    "                    tri = ' '.join(numbers).split()\n",
    "                    w = tri[-1]\n",
    "                    del tri[-1]\n",
    "                    s = ' '.join(tri)\n",
    "                    predict = predictWord(s,probab,vocab)\n",
    "                    if w == predict:\n",
    "                        score = score + 1\n",
    "                        #print(score,',',w,',',predict)\n",
    "                        #print(l[(int)(numbers[0])],' ',l[(int)(numbers[1])],' ',l[(int)(numbers[2])],' ',l[(int)(numbers[3])])\n",
    "    f.close()\n",
    "    print(\"Score : \",score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function : Calculate Perplexity after Add-1 Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_Perplexity(n,vocab,trigram,quadgram):\n",
    "    p = 1.0\n",
    "    with open('testfile.txt',buffering=20000,encoding='latin1') as f:\n",
    "        for line in f:\n",
    "            text = remove_punc(line)\n",
    "            tokens = text.split()\n",
    "            data = [tuple(tokens[i:i+4]) for i in range(len(tokens)-4+1)] \n",
    "            for quad in data:\n",
    "                count_quadgrams = 1\n",
    "                count_trigrams = len(vocab)\n",
    "                numbers = []\n",
    "                flag = 0\n",
    "                for ele in quad:\n",
    "                    if ele in vocab:\n",
    "                        numbers.append(str(vocab[ele]))\n",
    "                    else:\n",
    "                        flag = 1\n",
    "                        break\n",
    "                if flag == 0:\n",
    "                    four = ' '.join(numbers)\n",
    "                    three = ' '.join(numbers[0:3])\n",
    "                    if three in trigram:\n",
    "                        count_trigrams = count_trigrams + trigram[three]\n",
    "                    if four in quadgram:\n",
    "                        count_quadgrams = count_quadgrams + quadgram[four]\n",
    "                p=p*(((1/float(count_quadgrams))*count_trigrams)**(1./n))\n",
    "    print(\"Quadgram Perplexity : \",p)        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quadgram Perplexity :  2.2407648913689933\n",
      "Quadgram Perplexity :  2.2407648913689933\n",
      "Quadgram Perplexity :  2.2407648913689933\n",
      "Quadgram Perplexity :  2.2407648913689933\n",
      "1 loop, best of 3: 12.5 s per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "def main():\n",
    "    vocab = {}\n",
    "    probab = {}\n",
    "    trigram = {}\n",
    "    quadgram = {}\n",
    "    n = train_data(trigram,quadgram,vocab)\n",
    "    #add_probability(trigram,quadgram,probab)\n",
    "    #calculate_score(probab,vocab)\n",
    "    calculate_Perplexity(n,vocab,trigram,quadgram)\n",
    "if __name__== \"__main__\":\n",
    "  main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
