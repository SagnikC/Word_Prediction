{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "import math\n",
    "import string\n",
    "import re\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function : Create unigram dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_unigrams(unigrams,unigram):\n",
    "    for uni in unigrams:\n",
    "        stri = ''.join(uni)\n",
    "        if not unigram or stri not in unigram:\n",
    "            unigram[stri] = 1;\n",
    "        else:\n",
    "            unigram[stri] = unigram[stri] + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function : Create bigram dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_bigrams(bigrams,bigram):\n",
    "    for bi in bigrams:\n",
    "        stri = ' '.join(bi)\n",
    "        if not bigram or stri not in bigram:\n",
    "            bigram[stri] = 1;\n",
    "        else:\n",
    "            bigram[stri] = bigram[stri] + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function : Create trigram dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_trigrams(trigrams,trigram):\n",
    "    for tri in trigrams:\n",
    "        stri = ' '.join(tri)\n",
    "        if not trigram or stri not in trigram:\n",
    "            trigram[stri] = 1;\n",
    "        else:\n",
    "            trigram[stri] = trigram[stri] + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function : Create quadgram dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_quadgrams(quadgrams,quadgram):\n",
    "    for quad in quadgrams:\n",
    "        stri = ' '.join(quad)\n",
    "        if not quadgram or stri not in quadgram:\n",
    "            quadgram[stri] = 1;\n",
    "        else:\n",
    "            quadgram[stri] = quadgram[stri] + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function : Parameter Tuning Using Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def perform_grid_search(vocab,bi_probab,tri_probab,unigram,bigram,trigram,quadgram,tokens):\n",
    "    lambda1 = 0\n",
    "    lambda2 = 0\n",
    "    lambda3 = 0\n",
    "    max_score = 0\n",
    "    i=0\n",
    "    while i<=1:\n",
    "        j=0\n",
    "        while j<=1:\n",
    "            k=0\n",
    "            while k<=1:\n",
    "                if (i+j+k)<=1:\n",
    "                    probab_dict = {}\n",
    "                    for quad in quadgram:\n",
    "                        s = quad.split()\n",
    "                        w = s[-1]\n",
    "                        stri = ' '.join(s[0:3])\n",
    "                        p = perform_interpolation(quad,stri,s,quadgram,trigram,bigram,unigram,tokens,i,j,k,(1-i-j-k))\n",
    "                        if stri in probab_dict:\n",
    "                            if w not in probab_dict[stri] :\n",
    "                                probab_dict[stri][w] = p\n",
    "                                d = OrderedDict(sorted(probab_dict[stri].items(), key=lambda t: t[1]))\n",
    "                                probab_dict[stri] = d\n",
    "                        else:\n",
    "                            probab_dict[stri] = {}\n",
    "                            probab_dict[stri][w] = p\n",
    "                    score = calculate_score('held_out_corpus.txt',bi_probab,tri_probab,probab_dict,vocab)\n",
    "                    print(i,j,k,score,max_score)\n",
    "                    if score > max_score:\n",
    "                        lambda1 = i\n",
    "                        lambda2 = j\n",
    "                        lambda3 = k\n",
    "                        max_score = score\n",
    "                k = k + 0.1\n",
    "            j = j + 0.1\n",
    "        i = i + 0.1\n",
    "    return (lambda1,lambda2,lambda3,(1-lambda1-lambda2-lambda3))\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function : Perform interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def perform_interpolation(quad,stri,s,quadgram,trigram,bigram,unigram,tokens,lambda1,lambda2,lambda3,lambda4):\n",
    "    p = ( lambda1 * (quadgram[quad]/trigram[stri])) + (lambda2 * (trigram[' '.join(s[1:4])]/bigram[' '.join(s[1:3])])) + (lambda3 * (bigram[' '.join(s[2:4])]/unigram[str(s[2])])) + (lambda4 * (unigram[str(s[3])]/tokens))\n",
    "    return p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function : Create bigram probability dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def add_bi_probability(unigram,bigram,bi_probab):\n",
    "    for bi in bigram:\n",
    "        s = bi.split()\n",
    "        w = s[1]\n",
    "        stri = s[0]\n",
    "        p = float(bigram[bi])/unigram[stri]\n",
    "        if stri in bi_probab:\n",
    "            if w not in bi_probab[stri]:\n",
    "                bi_probab[stri][w] = p\n",
    "                d = OrderedDict(sorted(bi_probab[stri].items(), key=lambda t: t[1]))\n",
    "                bi_probab[stri] = d\n",
    "        else:\n",
    "            bi_probab[stri] = {}\n",
    "            bi_probab[stri][w] = p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function : Create trigram probability dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_tri_probability(bigram,trigram,tri_probab):\n",
    "    for tri in trigram:\n",
    "        s = tri.split()\n",
    "        w = s[-1]\n",
    "        stri = ' '.join(s[0:2])\n",
    "        p = float(trigram[tri])/bigram[stri]\n",
    "        if stri in tri_probab:\n",
    "            if w not in tri_probab[stri]:\n",
    "                tri_probab[stri][w] = p\n",
    "                d = OrderedDict(sorted(tri_probab[stri].items(), key=lambda t: t[1]))\n",
    "                tri_probab[stri] = d\n",
    "        else:\n",
    "            tri_probab[stri] = {}\n",
    "            tri_probab[stri][w] = p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function : Create quadgram probability dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def add_probability(vocab,bi_probab,tri_probab,unigram,bigram,trigram,quadgram,probab,tokens):\n",
    "    #(lambda1,lambda2,lambda3,lambda4) = perform_grid_search(vocab,bi_probab,tri_probab,unigram,bigram,trigram,quadgram,tokens)\n",
    "    lambda1 = 0.25\n",
    "    lambda2 = 0.25\n",
    "    lambda3 = 0.25\n",
    "    lambda4 = 0.25\n",
    "    for quad in quadgram:\n",
    "        s = quad.split()\n",
    "        w = s[-1]\n",
    "        stri = ' '.join(s[0:3])\n",
    "        p = perform_interpolation(quad,stri,s,quadgram,trigram,bigram,unigram,tokens,lambda1,lambda2,lambda3,lambda4)\n",
    "        if stri in probab:\n",
    "            if w not in probab[stri]:\n",
    "                probab[stri][w] = p\n",
    "                d = OrderedDict(sorted(probab[stri].items(), key=lambda t: t[1]))\n",
    "                probab[stri] = d\n",
    "        else:\n",
    "            probab[stri] = {}\n",
    "            probab[stri][w] = p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function : Create vocabulary list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_token_list(tokens,vocab):\n",
    "    newlist=[]\n",
    "    for word in tokens:\n",
    "        if word:\n",
    "            if not vocab or word not in vocab: \n",
    "                vocab[word] = len(vocab)\n",
    "            newlist.append(str(vocab[word]))\n",
    "    return newlist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function : Remove punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_punc(text):\n",
    "    for c in string.punctuation:\n",
    "        if c!='\\'':\n",
    "            text=text.replace(c,\" \")\n",
    "    text = text.replace(\"' \",\" \")\n",
    "    text = text.replace(\"\\n\",\" \")\n",
    "    answer = text.lower()\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function : Tokenize the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenize(text, ngrams,vocab):\n",
    "    clean_text = remove_punc(text)\n",
    "    tokens = create_token_list(clean_text.split(),vocab)\n",
    "    #print(tokens)\n",
    "    return [tuple(tokens[i:i+ngrams]) for i in range(len(tokens)-ngrams+1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function : Predict word using backoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predictWord(s,bi_probab,tri_probab,probab,vocab,rank = 0):\n",
    "    predict = \"\"\n",
    "    l = s.split()\n",
    "    tri = ' '.join(s[1:3])\n",
    "    bi = s[2]\n",
    "    if s in probab:\n",
    "        predict = list(probab[s].keys())[-1 - rank]\n",
    "    elif tri in tri_probab:\n",
    "        predict = list(tri_probab[tri].keys())[-1 - rank]\n",
    "    elif bi in bi_probab:\n",
    "        predict = list(bi_probab[bi].keys())[-1 - rank]\n",
    "    return predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing performed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_data(unigram,bigram,trigram,quadgram,vocab):\n",
    "    l = 0\n",
    "    with open('training_corpus.txt',buffering=20000,encoding='latin1') as f:\n",
    "        for line in f:\n",
    "            data = tokenize(line,1,vocab)\n",
    "            add_unigrams(data,unigram)\n",
    "            l = l + len(data)\n",
    "            data = tokenize(line,2,vocab)\n",
    "            add_bigrams(data,bigram)\n",
    "            data = tokenize(line,3,vocab)\n",
    "            add_trigrams(data,trigram)\n",
    "            data = tokenize(line,4,vocab)\n",
    "            add_quadgrams(data,quadgram)\n",
    "    f.close()\n",
    "    return l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function : Calculate score for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calculate_score(file_name,bi_probab,tri_probab,probab,vocab):\n",
    "    score = 0\n",
    "    l = list(vocab.keys())\n",
    "    with open(file_name,buffering=20000,encoding='latin1') as f:\n",
    "        for line in f:\n",
    "            text = remove_punc(line)\n",
    "            tokens = text.split()\n",
    "            data = [tuple(tokens[i:i+4]) for i in range(len(tokens)-4+1)]            \n",
    "            for quad in data:\n",
    "                numbers = []\n",
    "                flag = 0\n",
    "                for ele in quad:\n",
    "                    if ele in vocab:\n",
    "                        numbers.append(str(vocab[ele]))\n",
    "                    else:\n",
    "                        flag = 1\n",
    "                        break\n",
    "                if flag == 0:\n",
    "                    tri = ' '.join(numbers).split()\n",
    "                    w = tri[-1]\n",
    "                    del tri[-1]\n",
    "                    s = ' '.join(tri)\n",
    "                    predict = predictWord(s,bi_probab,tri_probab,probab,vocab)\n",
    "                    if w == predict:\n",
    "                        score = score + 1\n",
    "                        #print(score,',',w,',',predict)\n",
    "                        #print(l[(int)(numbers[0])],' ',l[(int)(numbers[1])],' ',l[(int)(numbers[2])],' ',l[(int)(numbers[3])])\n",
    "    f.close()\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function : Calculate Perplexity using Good-Turing Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calculate_perplexity_good_turing(n,vocab,quadgram):\n",
    "    freq = {}\n",
    "    for quad in quadgram:\n",
    "        if quadgram[quad] not in freq:\n",
    "            val = 0\n",
    "            for four in quadgram:\n",
    "                if quadgram[quad] == quadgram[four]:\n",
    "                    val = val +1\n",
    "            freq[quadgram[quad]] = val\n",
    "   \n",
    "    x_mean = 0\n",
    "    y_mean = 0\n",
    "    \n",
    "    for item in freq:\n",
    "        x_mean = x_mean + math.log(item)\n",
    "        y_mean = y_mean + math.log(freq[item])\n",
    "    \n",
    "    x_mean = x_mean/len(freq)\n",
    "    y_mean = y_mean/len(freq)\n",
    "    \n",
    "    num = 0\n",
    "    denom = 0\n",
    "    for item in freq:\n",
    "        x = math.log(item)\n",
    "        y = math.log(freq[item])\n",
    "        num = num + ((x - x_mean)*(y - y_mean))\n",
    "        denom = denom + math.pow((x - x_mean),2)\n",
    "    \n",
    "    b = num/denom\n",
    "    log_a = y_mean - (b * x_mean)\n",
    "    \n",
    "    p = 1.0\n",
    "    N = 0\n",
    "    i = 0\n",
    "    N_zero = 0\n",
    "    with open('testing_corpus.txt',buffering=20000,encoding='latin1') as f:\n",
    "        for line in f:\n",
    "            text = remove_punc(line)\n",
    "            tokens = text.split()\n",
    "            data = [tuple(tokens[i:i+4]) for i in range(len(tokens)-4+1)] \n",
    "            for quad in data:\n",
    "                c = 0\n",
    "                numbers = []\n",
    "                flag = 0\n",
    "                for ele in quad:\n",
    "                    if ele in vocab:\n",
    "                        numbers.append(str(vocab[ele]))\n",
    "                    else:\n",
    "                        flag = 1\n",
    "                        break\n",
    "                if flag == 0:\n",
    "                    four = ' '.join(numbers)\n",
    "                    if four in quadgram:\n",
    "                        c = quadgram[four]\n",
    "                N_c_plus_one = math.exp(log_a + (b * math.log(c+1)))\n",
    "                if c==0:\n",
    "                    N_zero = N_zero + 1\n",
    "                    N_c = N_zero\n",
    "                else:\n",
    "                    N_c = math.exp(log_a + (b * math.log(c)))\n",
    "                c_star = float((c+1) * N_c_plus_one)/N_c\n",
    "                p = p * ((1/float(c_star)) ** (1.0/n))\n",
    "                N = N + (N_c * c_star)\n",
    "                i = i + 1\n",
    "    p = p * (N ** (float(i)/n))\n",
    "    print(\"Perplexity using Good-Turing Smoothing : \",p)            \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function : Calculate Perplexity using Kneser-Ney Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calculate_perplexity_kneser_ney(n,vocab,unigram,bigram,trigram,quadgram):\n",
    "    p = 1.0\n",
    "    i = 0\n",
    "    with open('testing_corpus.txt',buffering=20000,encoding='latin1') as f:\n",
    "        for line in f:\n",
    "            if i == 1000:\n",
    "                break;\n",
    "            i = i + 1\n",
    "            text = remove_punc(line)\n",
    "            tokens = text.split()\n",
    "            data = [tuple(tokens[i:i+4]) for i in range(len(tokens)-4+1)] \n",
    "            for quad in data:\n",
    "                numbers = []\n",
    "                flag = 0\n",
    "                for ele in quad:\n",
    "                    if ele in vocab:\n",
    "                        numbers.append(str(vocab[ele]))\n",
    "                    else:\n",
    "                        flag = 1\n",
    "                        break\n",
    "                if flag == 0:\n",
    "                    D = 0.75\n",
    "                    num = 0\n",
    "                    val = 0\n",
    "                    w4 = numbers[3]\n",
    "                    w3 = numbers[2]\n",
    "                    for item in bigram:\n",
    "                        if item.split()[1] == w4:\n",
    "                            num = num + 1\n",
    "                        if item.split()[0] == w3:\n",
    "                            val = val + 1\n",
    "                    pkn4 = float(num)/len(bigram)\n",
    "                    pkn3 = (pkn4 * D * val)/float(unigram[w3])\n",
    "                    \n",
    "                    if ' '.join(numbers[2:4]) in bigram:\n",
    "                        pkn3 = pkn3 + (max(bigram[' '.join(numbers[2:4])] - D,0)/float(unigram[w3]))\n",
    "                    val = 0\n",
    "                    for item in trigram:\n",
    "                        if ' '.join(item.split()[0:2]) == ' '.join(numbers[1:3]):\n",
    "                            val = val + 1\n",
    "                    pkn2 = 0\n",
    "                    if ' '.join(numbers[1:3]) in bigram:\n",
    "                        pkn2 = (D * val * pkn3)/float(bigram[' '.join(numbers[1:3])])\n",
    "                        if ' '.join(numbers[1:4]) in trigram:\n",
    "                            pkn2 = pkn2 + (max(trigram[' '.join(numbers[1:4])] - D,0)/float(bigram[' '.join(numbers[1:3])]))\n",
    "                    pkn1 = 0\n",
    "                    val = 0\n",
    "                    for item in quadgram:\n",
    "                        if ' '.join(item.split()[0:3]) == ' '.join(numbers[0:3]):\n",
    "                            val = val + 1\n",
    "                    if ' '.join(numbers[0:3]) in trigram:\n",
    "                        pkn1 = (D * val * pkn2)/float(trigram[' '.join(numbers[0:3])])\n",
    "                        if ' '.join(numbers) in quadgram:\n",
    "                            pkn1 = pkn1 + (max(quadgram[' '.join(numbers)] - D,0)/float(trigram[' '.join(numbers[0:3])]))\n",
    "                    if pkn1 != 0:\n",
    "                        p = p * (1.0/(pkn1 ** (1.0/n)))\n",
    "    print(\"Perplexity using Kneser-Ney Smoothing : \",p)\n",
    "                                    \n",
    "                    \n",
    "                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function : Calculate Perplexity using Add-1 Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calculate_perplexity_add_one(n,vocab,trigram,quadgram):\n",
    "    p = 1.0\n",
    "    with open('testing_corpus.txt',buffering=20000,encoding='latin1') as f:\n",
    "        for line in f:\n",
    "            text = remove_punc(line)\n",
    "            tokens = text.split()\n",
    "            data = [tuple(tokens[i:i+4]) for i in range(len(tokens)-4+1)] \n",
    "            for quad in data:\n",
    "                count_quadgrams = 1\n",
    "                count_trigrams = len(quadgram)\n",
    "                numbers = []\n",
    "                flag = 0\n",
    "                for ele in quad:\n",
    "                    if ele in vocab:\n",
    "                        numbers.append(str(vocab[ele]))\n",
    "                    else:\n",
    "                        flag = 1\n",
    "                        break\n",
    "                if flag == 0:\n",
    "                    four = ' '.join(numbers)\n",
    "                    three = ' '.join(numbers[0:3])\n",
    "                    if three in trigram:\n",
    "                        count_trigrams = count_trigrams + trigram[three]\n",
    "                    if four in quadgram:\n",
    "                        count_quadgrams = count_quadgrams + quadgram[four]\n",
    "                p=p*(((1/float(count_quadgrams))*count_trigrams)**(1./n))\n",
    "    print(\"Perplexity after Add-1 Smoothing: \",p)        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score :  2812\n",
      "Perplexity after Add-1 Smoothing:  2.638884919558617\n",
      "Perplexity using Good-Turing Smoothing :  4.774585341840012\n",
      "Perplexity using Kneser-Ney Smoothing :  1.003290593918522\n"
     ]
    }
   ],
   "source": [
    "#%%timeit\n",
    "def main():\n",
    "    vocab = {}\n",
    "    probab = {}\n",
    "    tri_probab = {}\n",
    "    bi_probab = {}\n",
    "    unigram = {}\n",
    "    bigram = {}\n",
    "    trigram = {}\n",
    "    quadgram = {}\n",
    "    n = train_data(unigram,bigram,trigram,quadgram,vocab)\n",
    "    add_bi_probability(unigram,bigram,bi_probab)\n",
    "    add_tri_probability(bigram,trigram,tri_probab)\n",
    "    add_probability(vocab,bi_probab,tri_probab,unigram,bigram,trigram,quadgram,probab,n)\n",
    "    print(\"Score : \",calculate_score('testing_corpus.txt',bi_probab,tri_probab,probab,vocab))\n",
    "    calculate_perplexity_add_one(n,vocab,trigram,quadgram)\n",
    "    calculate_perplexity_good_turing(n,vocab,quadgram)\n",
    "    calculate_perplexity_kneser_ney(n,vocab,unigram,bigram,trigram,quadgram)\n",
    "if __name__== \"__main__\":\n",
    "  main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
